<!DOCTYPE html>
<html lang="en">
<head>
        <title>A Pelican Blog - Blog</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="../theme/css/main.css" type="text/css" />
                <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="A Pelican Blog Atom Feed" />
                
        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="../css/ie.css"/>
                <script src="../js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="../css/ie6.css"/><![endif]-->

                </head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="../">A Pelican Blog </a></h1>
                <nav><ul>
                                                                                                    <li class="active"><a href="../category/blog.html">Blog</a></li>
                                </ul></nav>
        </header><!-- /#banner -->
                
            

                            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="../regression-model-interpretation.html">Regression and Model Interpretation</a></h1> 
                    <footer class="post-info">
        <abbr class="published" title="2015-01-16T00:00:00">
                Fri 16 January 2015
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>

</footer><!-- /.post-info --><blockquote>
<p>$m = b_0 + b_1 x_1 + b_2 x_2 + \ldots + b_p x_p$</p>
<p>Do you see? We model the $m$; we say the $m$ is a function of various things, the $x$'s. Maybe one of the $x$'s is age, another is sex, a third is income, a fourth is BMI, a fifth is height, a sixth is presence of some gene, a seventh is whether the individual is a science major, an eighth is whether the individual is Caucasian, a ninth is high school GPA, a tenth is SAT score, an eleventh, a twelfth, thirteenth, and on and on and so on some more. You'd never make it as a sociologist unless you can think of at least two dozen entries.</p>
<p>Consider that the $x$ which represents whether the individual is Caucasian increases m. That does not therefore mean whites have higher GPAs than non-whites. No no no no no. No. It says, very indirectly and after manipulation most people forget to or don’t do, that given this model and these $x$'s, the probability whites have higher GPAs than non-whites is greater than 50%. (The exact probability can be calculated.)<sup id="fnref:regression-not-what-you-think"><a class="footnote-ref" href="#fn:regression-not-what-you-think" rel="footnote">1</a></sup></p>
</blockquote>
<p>흔히 선형 모델을 만들고 각 요소의 regression weight로 현실을 해석하려 한다. 위의 인용에서 사용된 예를 살펴보자. 만약 코카시언의 여부가 GPA의 선형 모델의 피쳐로 들어가고 그 weight가 양수라고 하자. 이를 백인이, 백인이 아닌 사람보다 GPA가 높다고 해석해서는 안 된다. 위의 인용에서 볼 수 있다시피 이는 무척 많은 가정을 깔고 들어간 후에야 백인의 GPA가 백인이 아닌 사람의 GPA보다 높을 확률이 50% 이상이라는 설명을 할 수 있다.</p>
<p>Bayesian의 관점에서 생각해보면 regularization은 우리가 세상에 대해 갖고 있는 prior knowledge를 반영한 것이다. 단순히 predictive accuracy를 높이기 위해 다양한 방법으로 이런 prior를 검증을 해보고 이를 바탕으로 예측을 하는 것은 괜찮을 수 있다. 하지만 모델로부터 세상을 해석하려고 할 때의 문제를 살펴보자. Sparse linear model을 생각해보면 아예 subset selection 문제로 접근하는 것도 가능하고 ridge나 lasso 등의 regularization 문제로 모델링 하는 것도 가능하다.</p>
<p><center>
<img src="https://www.evernote.com/shard/s25/sh/b3e173a3-3d91-4076-8b9f-5b0288cc76f5/be92f6f5a4ab2e6dddfb38407d5c163b/deep/0/Murphy---2012---Machine-Learning-A-Probabilistic-Perspective.pdf-(page-467-of-1098).png" alt="Sparse Model" style="width: 90%;"/>
</center></p>
<p>위의 예에서는 Lasso가 가장 좋은 predictive accuracy를 내지만 이는 문제의 특성에 따라 달라질 수 있다. 가령 위의 예에서 best subset과 ridge만 비교한다면 best subset이 더 예측력이 높기 때문에 이게 현실을 해석하는 용도로 사용되어도 괜찮은 것일까? 그렇다면 svi는 암 발병에 영향을 전혀 주지 않는 요소라고 말해도 괜찮은 것일까? 반대로 best subset과 lasso를 비교해보면 svi가 양의 weight를 가지므로 svi가 암 발병의 원인이 된다고 말할 수 있는 것일까?</p>
<p><center>
<img src="https://www.evernote.com/shard/s25/sh/f33e1fd4-5b6b-4820-9580-8f880fb242b2/562078df2ace0d03b73c0440c28b634a/deep/0/Murphy---2012---Machine-Learning-A-Probabilistic-Perspective.pdf-(page-468-of-1098).png" alt="Regularization" style="width: 90%;"/>
</center></p>
<p>같은 방법이라도 regularization의 강도를 얼마나 주느냐에 따라 다른 결과를 얻을 수 있다. CV를 거쳐서 hyper parameter를 결정했기 때문에 이것으로부터 현실을 해석해도 되는 것일까? 이런 종류의 모델 읽기 실수는 무척 저지르기 쉽다. 언제나 이런 해석에는 주의를 기울여야 한다.<sup id="fnref:pitfall"><a class="footnote-ref" href="#fn:pitfall" rel="footnote">2</a></sup></p>
<div class="footnote">
<hr />
<ol>
<li id="fn:regression-not-what-you-think">
<p><a href="http://wmbriggs.com/blog/?p=12524">Regression Isn’t What You Think</a>&#160;<a class="footnote-backref" href="#fnref:regression-not-what-you-think" rev="footnote" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:pitfall">
<p>이런 종류의 문제로 신뢰 구간, 유의 수준 등등도 있다. 진지한 연구자들조차 늘상 틀리는 개념들이다.&#160;<a class="footnote-backref" href="#fnref:pitfall" rev="footnote" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>                </article>
                            </aside><!-- /#featured -->
                            <section id="content" class="body">
                    <h1>Other articles</h1>
                    <hr />
                    <ol id="posts-list" class="hfeed">
                                                

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../principle-of-symmetry.html" rel="bookmark"
                           title="Permalink to 확률과 대칭성">확률과 대칭성</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2014-10-04T00:00:00">
                Sat 04 October 2014
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>

</footer><!-- /.post-info -->                <h2>Introduction</h2>
<p>수학 문제를 풀 때 유용한 전략 중 하나는 문제에 숨어있는 대칭성을 찾아서 이를 활용하는 것이다.</p>
<p>어떤 여행자가 강의 한쪽 편에서 맞은 편으로 가고자 한다.
밤새 심한 폭풍이 몰아쳐서 각 다리가 독립적으로 50%의 확률로 끊어졌을 수 있다.
이런 상황에서 여행자가 여전히 맞은 편으로 갈 수 있는 확률은 얼마인가?</p>
<p><center>
<img alt="Symmetric Bridge" src="https://farm6.staticflickr.com/5598/15430136565_bfb2f25682.jpg" />
</center></p>
<p>제일 ...</p>
                <a class="readmore" href="../principle-of-symmetry.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../bus-wait-2.html" rel="bookmark"
                           title="Permalink to 버스 대기 시간에 따른 전략">버스 대기 시간에 따른 전략</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2014-03-26T00:00:00">
                Wed 26 March 2014
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>

</footer><!-- /.post-info -->                <h2>Introduction</h2>
<p><a href="http://blog.shurain.net/2014/03/bus-wait-1.html">지난 글</a>에서 버스를 기다릴 때 <a href="http://en.wikipedia.org/wiki/Length_time_bias">length time bias</a>가 생기는 것을 살펴보았다.
이번 글에서는 지난 번에 논한 것을 바탕으로 시뮬레이션을 해서 최적의 전략이 무엇인지 찾아보도록 하자.</p>
<p>이번 글에서 다루는 버스 대기 시간과 거의 유사한 문제인 지하철 대기 시간과 관련된 문제가  <a href="http://www.amazon.com/Think-Bayes-Allen-B-Downey/dp/1449370780">Think Bayes</a>에서 <a href="http://www.greenteapress.com/thinkbayes/html/thinkbayes009.html">Red Line problem</a>으로 소개 ...</p>
                <a class="readmore" href="../bus-wait-2.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../bus-wait-1.html" rel="bookmark"
                           title="Permalink to 버스 대기 시간">버스 대기 시간</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2014-03-24T00:00:00">
                Mon 24 March 2014
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>

</footer><!-- /.post-info -->                <h2>Introduction</h2>
<p>얼마 전 지인 중 한 명이 다음의 문제를 페이스북에 공개하였다.
흥미로운 부분이 있기에 이를 논해보고자 한다.</p>
<blockquote>
<p>학교에서 집까지 가는 방법은 버스 A를 타고 10분 동안 이동한 뒤 내려서 5분 동안 걸어가는 방법과 버스 B를 타고 8분 동안 이동한 뒤 내려서 1분 동안 걸어가는 방법이 있다. 버스 A의 배차간격은 3분이고 ...</p></blockquote>
                <a class="readmore" href="../bus-wait-1.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../stumbleupon-evergreen-classification-challenge.html" rel="bookmark"
                           title="Permalink to StumbleUpon Evergreen Classification Challenge">StumbleUpon Evergreen Classification Challenge</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2013-11-08T00:00:00">
                Fri 08 November 2013
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>

</footer><!-- /.post-info -->                <h2>Introduction</h2>
<p>지난 8월 Kaggle에서 <a href="https://www.kaggle.com/c/stumbleupon">StumbleUpon Evergreen Classification Challenge</a>가 있었다.
이번 대회는 사용자에게 웹 문서를 추천해주는 서비스인 StumbleUpon에서 주최한 대회였다.
StumbleUpon이 서비스를 제공하면서 어떤 종류의 글은 발행 후 시간이 어느 정도 지나면 사람들에게 추천해주기 좋지 않은 반면 어떠한 글은 발행 후 시간과 무관하게 사람들에게 추천할 가치가 있는, 서로 다른 성격을 ...</p>
                <a class="readmore" href="../stumbleupon-evergreen-classification-challenge.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../naive-bayes-classifier.html" rel="bookmark"
                           title="Permalink to Naive Bayes Classifier">Naive Bayes Classifier</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2013-10-31T00:00:00">
                Thu 31 October 2013
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>

</footer><!-- /.post-info -->                <h2>Introduction</h2>
<p>스팸 문서 판별에 가장 쉽게 사용할 수 있는 기계 학습 기법으로 <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">나이브 베이즈 분류기</a>가 있다.
최근에 이와 관련된 간단한 발표를 할 일이 있어서 <a href="http://cl.ly/0s2U3L0Y2Q0L">관련 자료</a>를 만들어 보았다.
대부분의 내용은 Mathematicalmonk의 <a href="https://www.youtube.com/watch?v=8yvBqhm92xA&amp;list=PLD0F06AA0D2E8FFBA&amp;index=46">Naive Bayes classification 영상</a>을 참고하였다.</p>
<h2>Naive Bayes</h2>
<p>자세한 이야기는 발표 자료를 참고하기로 하고, 몇 가지 언급하고 ...</p>
                <a class="readmore" href="../naive-bayes-classifier.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../code-sprint-2013-round-2-post-mortem.html" rel="bookmark"
                           title="Permalink to Code Sprint 2013 Round 2 Post-mortem">Code Sprint 2013 Round 2 Post-mortem</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2013-08-27T00:00:00">
                Tue 27 August 2013
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>
<p>tags: <a href="../tag/code-sprint.html">code sprint</a><a href="../tag/forecasting.html">forecasting</a></p>
</footer><!-- /.post-info -->                <style>
.err {
    color: #000000;
    border: none;
}
</style>

<h2>Introduction</h2>
<p><a href="/2013/07/code-sprint-2013-round-2.html">지난 글</a>에서 내가 어떤 방법을 사용해서 <a href="http://codesprint.skplanet.com/2013/intro/round_02.htm">Code Sprint 라운드 2</a>에서 우승을 할 수 있었는지 설명하였다. 이번엔 지난 글에서 못다 한 이야기와 만약 나에게 주어진 시간이 충분했더라면 어떤 식의 접근을 했을지를 논하는 일종의 post-mortem을 이야기해보자.</p>
<h2>Bayesian Story</h2>
<p>기존 대회에서는 주어진 데이터를 posterior sample이라고 ...</p>
                <a class="readmore" href="../code-sprint-2013-round-2-post-mortem.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../code-sprint-2013-round-2.html" rel="bookmark"
                           title="Permalink to Code Sprint 2013 Round 2">Code Sprint 2013 Round 2</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2013-07-20T00:00:00">
                Sat 20 July 2013
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>
<p>tags: <a href="../tag/code-sprint.html">code sprint</a><a href="../tag/forecasting.html">forecasting</a></p>
</footer><!-- /.post-info -->                <h2>Introduction</h2>
<p>SK planet에서 정기적으로 Code Sprint라는 프로그래밍 경진 대회를 주최한다. 얼마 전에 Code Sprint 2013의 라운드 2 결과가 나왔는데 운이 좋게도 내가 1위를 할 수 있었다. 이번 대회의 목표는 과거의 교통정보 데이터를 사용하여 미래의 교통정보를 예측하는 것이었다.</p>
<p>대회 페이지의 설명을 그대로 옮겨보면, </p>
<blockquote>
<p>코드스프린트 Round2 문제에서는 2013년 4월부터 6월까지 3개월간의 T ...</p></blockquote>
                <a class="readmore" href="../code-sprint-2013-round-2.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../text-segmentation.html" rel="bookmark"
                           title="Permalink to Text Segmentation">Text Segmentation</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2013-05-02T00:00:00">
                Thu 02 May 2013
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>
<p>tags: <a href="../tag/crf.html">crf</a><a href="../tag/text-segmentation.html">text segmentation</a></p>
</footer><!-- /.post-info -->                <h2>Introduction</h2>
<p>모든 기계학습 기법이 그렇듯 CRF도 주어진 데이터에 따라 체감할 수 있는 성능 차이가 크다.
기계학습은 데이터를 바탕으로 어떤 모델을 만들어내는 방법이라고 생각할 수 있는데, 주어진 데이터가 우리가 원하는 모델을 만들어 내는데 필요한 정보를 갖고 있지 않으면 이는 불가능하다.</p>
<p><a href="http://homes.cs.washington.edu/~pedrod/">Pedro Domingos</a>는 기계학습을 정원을 가꾸는 것에 비유했다. <a href="#footnote1"><span id="ref1">[1]</span></a></p>
<ul>
<li>Seeds = Algorithms ...</li></ul>
                <a class="readmore" href="../text-segmentation.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../crf.html" rel="bookmark"
                           title="Permalink to Conditional Random Field">Conditional Random Field</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2013-04-16T00:00:00">
                Tue 16 April 2013
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>
<p>tags: <a href="../tag/crf.html">crf</a><a href="../tag/text-segmentation.html">text segmentation</a></p>
</footer><!-- /.post-info -->                <h2>Introduction</h2>
<p>Conditional random field는 (CRF) 레이블의 인접성에 대한 정보를 바탕으로 레이블을 추측하는 기계학습 기법이다.
CRF를 활용하여 여러 가지 재미있는 것들을 할 수 있는데, 이를 활용하는 방법에 대해 이야기하겠다. <a href="#footnote1"><span id="ref1">[1]</span></a></p>
<p>하지만 그래도 CRF가 어떤 식으로 동작하는 지 대충은 알아야 하니 대략적인 설명을 해보도록 하자.
보통 품사 태깅을 (Part-of-speech tagging) 예로 많이 ...</p>
                <a class="readmore" href="../crf.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../price-rights.html" rel="bookmark"
                           title="Permalink to Bayesian Approach to the Price is Right's Showdown">Bayesian Approach to the Price is Right's Showdown</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2013-03-12T00:00:00">
                Tue 12 March 2013
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>

</footer><!-- /.post-info -->                <p><a href="/2013/02/darkworld2.html">지난 글</a>에서 Observing Dark Worlds 대회에 1, 2위가
사용한 방법을 설명하면서 Bayesian 방식으로 문제에 접근하는 이야기를 했었다.
이런 Bayesian 방식을 쉽게 잘 설명한 글로
<a href="http://camdp.com/blogs/how-solve-price-rights-showdown">How to solve the Price is Right's Showdown</a>이라는
블로그 글이 있다.</p>
<p>이 글은 <a href="http://en.wikipedia.org/wiki/The_Price_Is_Right">The Price Is Right</a>이라는
TV 쇼의 마지막 대결 The ...</p>
                <a class="readmore" href="../price-rights.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../darkworld2.html" rel="bookmark"
                           title="Permalink to Dark World Part II">Dark World Part II</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2013-02-20T00:00:00">
                Wed 20 February 2013
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>
<p>tags: <a href="../tag/kaggle.html">kaggle</a><a href="../tag/dark-world.html">dark world</a></p>
</footer><!-- /.post-info -->                <h2>Introduction</h2>
<p><a href="/2013/02/darkworld1.html">지난 글</a>에 이어 <a href="http://www.kaggle.com/c/DarkWorlds">Observing Dark Worlds</a> 대회에 대한 이야기를 계속하겠다.
이번에는 1, 2위가 사용한 방법의 큰 그림을 그리면서 가능하면 자세하게 설명을 하고자 한다.</p>
<p>본인들이 직접 자신들의 방법을 설명한 글은 다음의 링크에서 볼 수 있다.</p>
<ul>
<li><a href="http://timsalimans.com/observing-dark-worlds/">Observing Dark Worlds (1위)</a></li>
<li><a href="http://homepages.inf.ed.ac.uk/imurray2/pub/12kaggle_dark/">A Bayesian approach to Observing Dark Worlds (2위)</a></li>
</ul>
<h2>Decision Theory ...</h2>
                <a class="readmore" href="../darkworld2.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            

                 
                        <li><article class="hentry">    
                <header>
                    <h1><a href="../darkworld1.html" rel="bookmark"
                           title="Permalink to Dark World Part I">Dark World Part I</a></h1>
                </header>
                
                <div class="entry-content">
                <footer class="post-info">
        <abbr class="published" title="2013-02-18T00:00:00">
                Mon 18 February 2013
        </abbr>

        <p>In <a href="../category/blog.html">Blog</a>. </p>
<p>tags: <a href="../tag/kaggle.html">kaggle</a><a href="../tag/dark-world.html">dark world</a></p>
</footer><!-- /.post-info -->                <h2>Introduction</h2>
<p>2012년 겨울에 <a href="http://www.kaggle.com/">Kaggle</a>에 <a href="http://www.kaggle.com/c/DarkWorlds">Observing Dark Worlds</a>라는 대회가 열렸다.
대회의 목표는 하늘 사진을 찍고 어떤 위치에 암흑 물질이 있는지 찾아내는 것이었다.</p>
<p>암흑 물질은 빛과 상호작용하지 않으면서 질량을 가지는 물질이다.
자체적으로 빛을 내뿜거나 흡수하지는 않지만 질량을 갖기 때문에 그 중력에 의한 영향으로 주변의 빛에 영향을 줄 수가 있다.</p>
<p><center>
<img alt="Dark matter halo" src="/static/images/arc.png" />
</center></p>
<p>위의 ...</p>
                <a class="readmore" href="../darkworld1.html">read more</a>
                                </div><!-- /.entry-content -->
            </article></li>
                            </ol><!-- /#posts-list -->
                                                    </section><!-- /#content -->
                    <section id="extras" class="body">
                        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>