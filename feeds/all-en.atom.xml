<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>sh.</title><link href="http://blog.shurain.net/" rel="alternate"></link><link href="http://feeds.feedburner.com/feeds/all-en.atom.xml" rel="self"></link><id>http://blog.shurain.net/</id><updated>2013-03-12T00:00:00+00:00</updated><entry><title>Bayesian Approach to the Price is Right's Showdown</title><link href="http://blog.shurain.net/2013/03/price-irights.html" rel="alternate"></link><updated>2013-03-12T00:00:00+00:00</updated><author><name>Sungjoo Ha</name></author><id>tag:blog.shurain.net,2013-03-12:2013/03/price-irights.html</id><summary type="html">&lt;p&gt;&lt;a href="/2013/02/darkworld2.html"&gt;지난 글&lt;/a&gt;에서 Observing Dark Worlds 대회에 1, 2위가
사용한 방법을 설명하면서 Bayesian 방식으로 문제에 접근하는 이야기를 했었다.
이런 Bayesian 방식을 쉽게 잘 설명한 글로
&lt;a href="http://camdp.com/blogs/how-solve-price-rights-showdown"&gt;How to solve the Price is Right's Showdown&lt;/a&gt;이라는
블로그 글이 있다.&lt;/p&gt;
&lt;p&gt;이 글은 &lt;a href="http://en.wikipedia.org/wiki/The_Price_Is_Right"&gt;The Price Is Right&lt;/a&gt;이라는
TV 쇼의 마지막 대결 The Showcase를 Bayesian 방식으로 풀어보는 시도에 대한 이야기하고 있다.
문제에 대한 자세한 정보는 원문을 참고하길 바란다.&lt;/p&gt;
&lt;p&gt;전체적으로는 prior belief를 설정하고 likelihood 계산을 위한 모델 설정 뒤에
&lt;a href="https://github.com/pymc-devs/pymc"&gt;PyMC&lt;/a&gt; 라이브러리를 사용하여 MCMC 계산을 한다.
그리고 loss function을 정의하여 그에 따른 expected loss optimization을 수행하는 전통적인 구조를 잘 보여준다.
같은 기법이 다른 문제에 적용된 사례이니 지난 글의 내용이 잘 이해가 되지 않았던 분들은 한 번 읽어보시면 도움이 될 것이다.&lt;/p&gt;
&lt;p&gt;글의 내용은 오픈 소스 책인
&lt;a href="https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers"&gt;Probabilistic Programming and Bayesian Methods for Hackers in Python&lt;/a&gt;의
내용을 따와서 많이 수정하여 만들었다고 한다.
아직 책의 내용을 살펴볼 기회는 없었지만 기초적인 Bayesian 기법에 대해 실제로 사용해보는 것을 위주로&lt;a href="#footnote1"&gt;&lt;span id="ref1"&gt;[1]&lt;/span&gt;&lt;/a&gt;
쓰여 있다고 하니 이런 내용에 관심 있는 사람들은 한 번 보면 좋을 것이다.&lt;/p&gt;
&lt;p&gt;&lt;span id="footnote1"&gt;
&lt;a href="#ref1"&gt;[1]&lt;/a&gt;: 사람들이 질려 할만한 수학은 가능하면 2순위로 미루고
&lt;/span&gt;&lt;/p&gt;</summary></entry><entry><title>Dark World Part II</title><link href="http://blog.shurain.net/2013/02/darkworld2.html" rel="alternate"></link><updated>2013-02-20T00:00:00+00:00</updated><author><name>Sungjoo Ha</name></author><id>tag:blog.shurain.net,2013-02-20:2013/02/darkworld2.html</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href="/2013/02/darkworld1.html"&gt;지난 글&lt;/a&gt;에 이어 &lt;a href="http://www.kaggle.com/c/DarkWorlds"&gt;Observing Dark Worlds&lt;/a&gt; 대회에 대한 이야기를 계속하겠다.
이번에는 1, 2위가 사용한 방법의 큰 그림을 그리면서 가능하면 자세하게 설명을 하고자 한다.&lt;/p&gt;
&lt;p&gt;본인들이 직접 자신들의 방법을 설명한 글은 다음의 링크에서 볼 수 있다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://timsalimans.com/observing-dark-worlds/"&gt;Observing Dark Worlds (1위)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://homepages.inf.ed.ac.uk/imurray2/pub/12kaggle_dark/"&gt;A Bayesian approach to Observing Dark Worlds (2위)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Decision Theory&lt;/h2&gt;
&lt;p&gt;1, 2위의 전략에 대한 설명에 앞서 decision theory에 대한 이야기를 간단하게 하도록 하겠다.&lt;/p&gt;
&lt;p&gt;어떤 선택이 얼마나 좋은 선택이었는지 판단하기 위해서 우리는 선택의 성과를 측정할 수 있어야 한다.
보통 이런 때에는 loss function이라는 개념을 도입하여 이를 설명한다.
직관적으로, loss function은 선택의 결과와 관련된 "비용"을 나타내게 된다.
적은 비용이 드는 선택이 큰 비용이 드는 선택에 비해 좋은 것은 자명하다.&lt;/p&gt;
&lt;p&gt;이제 우리는 선택의 성과를 측정하는 방법이 생겼으니 좋은 선택과 나쁜 선택을 구분할 수 있다.
이런 설정에서 앞으로 나아갈 자연스러운 방향은 loss의 기대값을 최소화하는 방향으로 이어지게 된다.
즉, 우리는 미리 정해진 loss function이 주어지면 expected loss를 최소화하는 어떤 선택 전략을 찾아서 이를 사용하면 된다.
그래서 실제로 expected loss를 최소화하는 문제를 푸는 시도를 하게 되는데, 이 문제를 풀다 보면 결국 posterior distribution의 계산을 해야 하는 문제에 당면하게 된다.
즉, posterior distribution의 계산이 우리의 관심사가 되게 된다.&lt;/p&gt;
&lt;p&gt;Decision theory와 관련된 내용은 Mathematicalmonk의 &lt;a href="http://www.youtube.com/watch?v=KYRAO8f5rXA&amp;amp;feature=share&amp;amp;list=PLD0F06AA0D2E8FFBA"&gt;decision theory 관련 동영상&lt;/a&gt;을 참고하기 바란다.&lt;/p&gt;
&lt;h2&gt;Bayesian Approach&lt;/h2&gt;
&lt;p&gt;전에도 언급했지만 1, 2위가 사용한 기법은 전통적인 베이지안 접근 방법이었다.
베이지안 접근 방법은 다음과 같다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prior distribution을 만든다.&lt;/li&gt;
&lt;li&gt;Likelihood 계산을 위한 모델을 만든다.&lt;/li&gt;
&lt;li&gt;Bayes' theorem을 사용하여 posterior distribution을 계산한다.&lt;/li&gt;
&lt;li&gt;Posterior distribution에 대한 expected loss를 최소화한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이게 도대체 무슨 뜻인지 이야기를 해보자.&lt;/p&gt;
&lt;p&gt;베이지안 접근 방법은 결국 세상 모든 것을 어떠한 확률식으로 표현하는 것으로 생각해볼 수 있다.&lt;a href="#footnote1"&gt;&lt;span id="ref1"&gt;[1]&lt;/span&gt;&lt;/a&gt;
우리가 보통 궁금해하는 것은, 앞 절에서도 설명하였지만, posterior distribution이다.
이는 주어진 데이터와 모델을 설명하는 모델 패러미터에 대한 식으로 나타날 수 있다.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img alt="Bayes' Theorem" src="/static/images/bayestheorem.png" /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;위의 수식에서 D는 우리가 관측할 수 있는 데이터이고 θ는 모델을 설명하는 모델 패러미터라고 하자.
Posterior distribution은 좌변을 가리키고 likelihood는 우변의 좌측에 있는 항이며 prior distribution은 우변의 우측에 있는 항이다.&lt;/p&gt;
&lt;p&gt;우리는 보통 어떤 데이터를 가지고 있고, 이를 토대로 모델에 대한 것을 알고 싶어 한다. 하지만 posterior distribution을 바로 계산하기는 쉽지 않다.
그렇지만 어떤 모델과 데이터가 있을 때, 그 likelihood를 계산하는 것은 상대적으로 쉬운 문제이다.
그리고 prior distribution은 결국 우리가 데이터를 관측하기 전에 각 모델이 어떤 분포를 이루고 있는지에 대한 믿음을 확률식으로 표현한 것이다.
이 두 값을 활용하여 posterior distribution을 계산하는 것이 가능하다. &lt;a href="#footnote2"&gt;&lt;span id="ref2"&gt;[2]&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;위의 접근 방법을 거꾸로 따라가 보자.
우리는 expected loss를 최소화하고 싶은데 이는 결국 posterior distribution을 얻는 문제로 귀결된다고 하였다.
Posterior distribution을 얻는 것은 바로 위에서 설명하였다시피 likelihood와 prior distribution이 있으면 Bayes' theorem을 사용하여 계산할 수 있다.
그러므로 우리에게 필요한 것은 likelihood 계산을 위한 모델과 prior distribution이다.
이 두 확률 분포를 결정할 수 있으면 위의 방법을 순차적으로 적용하여 우리가 원하는 대로 expected loss를 최소화할 수 있다.&lt;/p&gt;
&lt;h2&gt;Bayesian Approach for Dark World&lt;/h2&gt;
&lt;p&gt;이제 실제로 대회에서 사용된 방법을 차근차근 살펴보도록 하자.
문제 자체를 생각해보면 우리가 알고 싶은 것은 각 헤일로의 위치이다.
그리고 우리가 들고 있는 데이터는 은하의 위치와 그 ellipticity 값이다.
이 두 가지를 가지고 베이지안 접근을 취해보자.&lt;/p&gt;
&lt;h3&gt;Prior Distribution&lt;/h3&gt;
&lt;p&gt;Prior distribution은 우리가 데이터를 보기 전에 각 모델에 대해 갖는 믿음의 확률 분포이다.
이 문제의 경우에는 우리가 데이터(은하의 정보)를 보기 전에 헤일로의 위치가 어떤 식으로 분포하고 있을 것인지에 대한 분포가 될 것이다.
문제의 가정에 포함되어 있었는지는 기억이 나지 않지만, 이는 자연스럽게 uniform distribution이 된다.
이는 데이터를 살펴보고 편향이 있는지 검사하여 확인할 수도 있을 것이다.&lt;/p&gt;
&lt;h3&gt;Model and Likelihood&lt;/h3&gt;
&lt;p&gt;매우 좋은 모델을 만드는 것은 사실 어려운 문제이다.
그러나 본 문제는 이미 벤치마크 코드에 어느 정도 동작하는 모델이 있었다.
주어진 모델은 완벽하지는 않지만 이를 조금만 확장하면 그럭저럭 괜찮은 모델을 만들 수 있다.&lt;/p&gt;
&lt;p&gt;우선 가장 처음 해야 하는 것은 ellipticity에 대한 가정이다.
만약 헤일로가 없다면 각 은하의 ellipticity는 어떤 분포를 띌 것인가?
이 질문에 답할 수 있어야 모델을 만들 수 있다.
우리는 결국 각 헤일로가 은하에 미치는 영향을 ellipticity를 통해서 계산할 것이기 때문이다.&lt;/p&gt;
&lt;p&gt;다행히도 각 은하의 ellipticity는 문제의 가정에서 특정한 편향이 없다고 주어졌다.
즉, 평범하게 평균이 0인 정규 분포를 가정하면 된다.
이 정규 분포를 설명하는 데 필요한 표준편차는 우리에게 주어진 데이터를 살펴보고 얻을 수 있다.&lt;/p&gt;
&lt;p&gt;이제 모델을 만들어보자.
벤치마크 코드로 주어진 모델은 하나의 헤일로가 어떤 은하에 가하는 힘은 거리에 반비례하는 접선 방향의 ellipticity 계산을 통해 알 수 있다 하였다.
이는 더 정교한 모델로 바꿀 여지가 많이 있다.&lt;/p&gt;
&lt;p&gt;우선 각 헤일로에 질량을 부여하도록 하자.
질량이 큰 헤일로가 더 큰 영향을 주는 것은 자연스러워 보인다.
은하의 질량 분포는 데이터를 살펴보아서 추측할 수 있을 것이다.
앞선 글에서도 언급하였지만, 데이터를 살펴보면 하나의 큰 헤일로와 작은 헤일로가 있으므로 이를 고려하여 질량의 분포를 예측하면 될 것이다.&lt;/p&gt;
&lt;p&gt;그리고 데이터를 살펴보면 힘이 거리에 반비례하지만은 않는 것을 볼 수 있다.
헤일로가 은하에 가하는 힘은 단순히 거리에 반비례하기보다는 어떤 한계점이 있어서 일정 거리 이상으로 멀어지기 전에는 고정되어 있음을 알 수 있다.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img alt="Distance function" src="/static/images/distance_function.png" /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;아직 더 정교화할 여지가 남아 있지만 &lt;a href="#footnote3"&gt;&lt;span id="ref3"&gt;[3]&lt;/span&gt;&lt;/a&gt;
이 정도만 하더라도 꽤 훌륭한 모델이 된다.
이를 수식으로 표현하면 다음과 같다.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img alt="Distance function" src="/static/images/likelihood.png" /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;즉, 모델 (헤일로의 위치) x가 주어졌을 때, 그 모델에 의해 지금의 데이터 (은하의 ellipticity) e가 관측될 likelihood는 우리가 가정한 모델이 가하는 힘을 평균으로 갖는 정규 분포를 따른다는 것이다.
이는 바꿔 말하면 우리가 가정한 모델이 가하는 힘을 제거하고 나면 은하의 ellipticity는 평균이 0인 정규분포를 따를 것이라는 말이 된다.&lt;/p&gt;
&lt;p&gt;여기에 더해서 2위를 차지한 사람은 헤일로의 중심에 가까워지면 노이즈가 심해져서 표준편차가 바뀔 것이라는 가정을 더하였다.
어찌 되었든 양쪽 다 모델의 모양은 거의 유사하다.&lt;/p&gt;
&lt;p&gt;이렇게 만들어진 likelihood는 어떤 임의의 헤일로 위치와 그에 상응하는 은하의 정보가 있을 때 그런 상황이 얼마나 그럴싸한지를 표현하게 된다.&lt;/p&gt;
&lt;h3&gt;Posterior Distribution&lt;/h3&gt;
&lt;p&gt;Bayes' theorem 자체는 간단해 보이지만 실제로 posterior distribution을 계산하는 것은 어려운 문제이다.
왜냐하면 분모의 계산이 무척 어렵기 때문이다.
보통 이런 꼴의 식은 어떤 다른 패러미터에 대해 적분/덧셈을 하면 풀어낼 수 있는데, 적분 혹은 덧셈은 미천한 인간이 풀어내기 어려운 경우가 대부분이다.&lt;/p&gt;
&lt;p&gt;비록 posterior distribution을 해석적으로 풀어낼 수는 없지만 다른 방법을 써서 이를 근사하는 것이 가능하다.
그중 한 가지 방법이 샘플링이다.
우리가 알고 싶은 분포에서 샘플을 뽑아낼 수 있으면, 그 샘플을 사용하여 원래 알고 싶었던 분포를 근사하는 것이 가능하다.
하지만 사실 이 또한 어려운 문제이다.
그러나 목표로 하는 분포의 값을 정규화하는 상수를 제외한 나머지 부분을 계산할 수 있으면 (target distribution is known up to a normalizing constant) 샘플링을 할 수 있는 Monte Carlo Markov Chain(MCMC)이라는 기법이 있다.
우리는 likelihood와 prior distribution의 값을 계산할 수 있으므로 결국 MCMC를 사용하여 원하는 대로 posterior distribution으로부터 샘플링하는 것이 가능하다.&lt;/p&gt;
&lt;p&gt;MCMC에 대한 자세한 이야기는 나중에 다른 글에서 더 소개할 기회가 있을 것으로 여겨진다.
더 자세한 설명이 궁금하다면 Mathematicalmonk의 &lt;a href="http://www.youtube.com/watch?v=12eZWG0Z5gY&amp;amp;feature=share&amp;amp;list=PLD0F06AA0D2E8FFBA"&gt;MCMC 설명&lt;/a&gt;을 참고하길 바란다.&lt;/p&gt;
&lt;p&gt;1위는 아주 기본적인 Metropolis-Hastings 기법을 사용하였고, 2위는 그보다 더 세련된 Slice sampler를 사용하였는데 둘 다 원하는 분포에서 샘플링을 한다는 본질에는 차이가 없다.
MCMC 자체가 왜 동작하는지 이해하는 것은 꽤 많은 설명이 필요하지만 그 구현 자체는 무척 간단하다.&lt;a href="#footnote4"&gt;&lt;span id="ref4"&gt;[4]&lt;/span&gt;&lt;/a&gt;
간단히 Metropolis-Hastings 기법을 이번 문제에 적용하면 다음과 같다.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="n"&gt;Choose&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt; &lt;span class="n"&gt;halo&lt;/span&gt; &lt;span class="n"&gt;position&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;number&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;halos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
       &lt;span class="n"&gt;Sample&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="n"&gt;by&lt;/span&gt; &lt;span class="n"&gt;randomly&lt;/span&gt; &lt;span class="n"&gt;moving&lt;/span&gt; &lt;span class="n"&gt;jth&lt;/span&gt; &lt;span class="n"&gt;halo&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
       &lt;span class="n"&gt;Calculate&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;likelihood&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
       &lt;span class="n"&gt;Sample&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt; &lt;span class="n"&gt;uniform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
       &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;log&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;log&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
           &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;
       &lt;span class="nl"&gt;else:&lt;/span&gt;
            &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;Output&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;...,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;알고리즘 자체는 아주 단순한 것을 알 수 있다.
놀랍게도 이렇게 출력된 x들이 우리가 원하던 posterior distribution으로부터 샘플한 값들이 된다.&lt;/p&gt;
&lt;h3&gt;Minimizing Expected Loss&lt;/h3&gt;
&lt;p&gt;Loss function은 문제로부터 주어져 있고 posterior distribution에서 뽑은 샘플도 있으므로 이제 expected loss를 구할 수 있다.
임의의 헤일로 배치 x가 주어지면 이 x의 expected loss는 각 posterior distribution에서 뽑은 샘플 하나하나를 매번 정답이라고 가정하고 구한 loss의 평균이 된다.
우리의 목표는 이를 최소화하는 x를 찾는 것이다.
이는 간단하게는 랜덤하게 많은 수의 x를 만들어보고 그 중 가장 좋은 것을 선택하는 방식을 취할 수 있을 것이다.&lt;/p&gt;
&lt;p&gt;1위를 차지한 사람은 expected loss를 계산하면서 gradient를 계산할 수 있도록 짜서 local optimization이 가능하도록 하였다.
그리고 지역 최적점에서 빠져나올 수 있도록 random multi-start를 수행하게 하였다.&lt;/p&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;그동안 긴 시간 공부를 하였고 소프트웨어 엔지니어로서 일도 꽤 하였는데, 그런 경험을 통해 배운 것이 하나 있다면 그건 바로 내 생각에는 구멍이 많다는 것이다.
내가 앞뒤로 모든 것을 꿰고 있는 주제가 아니라면 당연해 보이는 것들에도 늘 구멍이 있었다.
내가 프로그래머가 되어서 좋다고 생각하는 점 중 하나는 그런 구멍의 존재를 깨달을 수 있었던 부분이다.
어떤 개념/생각을 구현하는 것은 나로 하여금 생각을 아주 구체화하도록 강제한다.
논문을 읽는 동안은 전부 이해한 것 같지만 막상 구현하고자 하면 벽에 부딪히는 부분이 한둘이 아니다.
이번 대회를 통해서 실제로 베이지안 접근 방법을 적용하는 것을 보았고, 그걸 구현한 구현체도 살펴보니 많은 부분이 체화되는 것을 느낄 수 있었다.
그런 측면에서 아주 얻은 것이 많다고 할 수 있다.&lt;/p&gt;
&lt;p&gt;&lt;span id="footnote1"&gt;
&lt;a href="#ref1"&gt;[1]&lt;/a&gt;: 단순하게 말해서 그렇다는 것이다.
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span id="footnote2"&gt;
&lt;a href="#ref2"&gt;[2]&lt;/a&gt;: 사실 우변의 분모도 계산해야 하고 그 자체는 어려운 문제이다. 하지만 이는 데이터 D에 의해서만 결정되는 값이므로 불변이다.
그러므로 이 문제를 우회할 수 있는 방법이 있다.
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span id="footnote3"&gt;
&lt;a href="#ref3"&gt;[3]&lt;/a&gt;: 실제로는 암흑 물질의 영향을 받아서 은하의 관측 위치가 바뀌는 등 훨씬 더 복잡한 현상들이 일어난다고 한다.
&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span id="footnote4"&gt;
&lt;a href="#ref4"&gt;[4]&lt;/a&gt;: 그러므로 무척 강력한 도구이다. 최초의 MCMC 기법인 Metropolis 알고리즘은 20세기 10대 알고리즘으로 선정되기도 하였다.
&lt;/span&gt;&lt;/p&gt;</summary><category term="kaggle"></category><category term="dark world"></category></entry><entry><title>Dark World Part I</title><link href="http://blog.shurain.net/2013/02/darkworld1.html" rel="alternate"></link><updated>2013-02-18T00:00:00+00:00</updated><author><name>Sungjoo Ha</name></author><id>tag:blog.shurain.net,2013-02-18:2013/02/darkworld1.html</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;2012년 겨울에 &lt;a href="http://www.kaggle.com/"&gt;Kaggle&lt;/a&gt;에 &lt;a href="http://www.kaggle.com/c/DarkWorlds"&gt;Observing Dark Worlds&lt;/a&gt;라는 대회가 열렸다.
대회의 목표는 하늘 사진을 찍고 어떤 위치에 암흑 물질이 있는지 찾아내는 것이었다.&lt;/p&gt;
&lt;p&gt;암흑 물질은 빛과 상호작용하지 않으면서 질량을 가지는 물질이다.
자체적으로 빛을 내뿜거나 흡수하지는 않지만 질량을 갖기 때문에 그 중력에 의한 영향으로 주변의 빛에 영향을 줄 수가 있다.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img alt="Dark matter halo" src="/static/images/arc.png" /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;위의 이미지에서는 암흑 물질의 영향에 의해 은하가 내뿜는 빛이 호(arc)를 그리는 것을 볼 수 있다.
이런 효과에 의해 암흑 물질을 직접 관측할 수는 없지만 그 위치를 짐작하는 것이 가능하다.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img alt="Effect of dark matter halo" src="/static/images/reorderdarkmatter.png" /&gt;&lt;/p&gt;
&lt;p&gt;Credit: Observing Dark Worlds Kaggle Competition
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;만약 빛을 내는 은하들이 만약 모두 원형이라면 암흑 물질에 의해 타원형으로 관측되는 모습이 바뀔 것이므로 이를 통해 쉽게 암흑 물질의 위치를 추측할 수 있다.
하지만 현실은 그렇게 만만하지 않아서 애초에 은하들이 타원형을 띄고 있다.
그렇기 때문에 은하들이 애초에 그런 모양인지 암흑 물질의 영향으로 뒤틀린 것인지 알아내는 것은 쉬운 문제가 아니다.&lt;/p&gt;
&lt;h2&gt;Details&lt;/h2&gt;
&lt;p&gt;문제를 풀기 위해 주어진 데이터는 암흑 물질의 위치가 주어진 training set 300개와 과 암흑 물질의 위치가 주어지지 않은 test set 120개였다.
각 데이터는 시뮬레이션으로 생성된 하늘 데이터로서 각 하늘에는 1~3개의 암흑 물질과 300~740개의 은하가 존재하도록 만들어졌다.
각 은하는 x, y 좌표와 타원의 정도인 ellipticity를 나타내는 값 e1과 e2가 주어졌다.&lt;/p&gt;
&lt;p&gt;데이터와 함께 두 개의 벤치마크 코드가 주어졌다.
각각 시그널 기반의 방법과 모델 기반의 방법인데 접근 방법이 비슷해 보이지만 실제로는 꽤 다른 접근 방법이다.
양쪽 다 하늘을 적당한 크기의 격자로 나누고 암흑 물질이 한 격자의 중심에 위치해 있다고 가정한다.
시그널 기반의 방식은 이제 위의 가정하에 해당 암흑 물질이 모든 은하에 미치고 있는 시그널이 얼마나 되는지 계산하여 그 합이 가장 큰 격자를 선택하는 방법이다.
모델 기반의 방식은 암흑 물질이 각 은하에 가하는 힘의 크기가 1/r로 줄어들 것이라는 모델을 가정하고 해당 모델이 얼마나 잘 들어맞는지를 계산하여 가장 그럴싸한 격자를 선택하는 식으로 구현되어 있었다.&lt;/p&gt;
&lt;p&gt;데이터 및 벤치마크와 관련된 자세한 내용은 대회 공식 페이지인 &lt;a href="http://www.kaggle.com/c/DarkWorlds"&gt;Observing Dark Worlds&lt;/a&gt; 및
&lt;a href="http://blog.kaggle.com/2012/10/12/observing-dark-worlds-a-beginners-guide-to-dark-matter-how-to-find-it/"&gt;Kaggle tutorial 블로그&lt;/a&gt;에 가면 얻을 수 있다.&lt;/p&gt;
&lt;h2&gt;Approach&lt;/h2&gt;
&lt;p&gt;내가 접근한 방식을 설명하기 전에 몇 가지 이야기를 꺼내보자.
일단 나는 고득점을 하지는 못했다.
그리고 내가 작업했던 많은 부분을 실제로 제출하지도 못한 채로 대회를 마감해야 했다.
그렇기에 내가 서술하는 기법들이 얼마나 좋은지는 실제로 판단해보지는 못하였다.
이런 첨언을 미리 해두고 내가 어떤 식으로 문제에 접근하였는지 설명해보자.&lt;/p&gt;
&lt;h3&gt;Visualization&lt;/h3&gt;
&lt;p&gt;어떠한 문제든 다루는 데이터가 어느 정도 복잡하다면 통계를 내고 시각화를 통해 직관을 키우는 것이 중요하다.
그래서 시각화를 위한 노력을 어느 정도 하였다.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img alt="Signal-based on sky 1" src="/static/images/signal_001.png" /&gt;
&lt;img alt="Signal-based on sky 298" src="/static/images/signal_298.png" /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;위의 그림은 시그널 기반의 벤치마크 코드에 약간 수정을 가한 코드로 얻어낸 답을 시각화한 것이다.
히트맵을 통해 각 위치가 얼마나 그럴싸한지 나타내도록 하였다.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img alt="Model-based on sky 31" src="/static/images/likelihood_031.png" /&gt;
&lt;img alt="Model-based on sky 278" src="/static/images/likelihood_278.png" /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;비슷한 방식으로 기존의 모델 기반의 벤치마크 코드에 약간의 수정을 가미한 코드로 얻어낸 결과이다.&lt;/p&gt;
&lt;p&gt;시각화를 통해서 많은 것을 쉽게 얻을 수가 있다.
시각화는 내가 만들어낸 기법이 얼마나 말이 되는 결과를 내고 있는지를 직관적으로 판단할 수 있는 좋은 기법이며 예상치 못했던 사실을 발견할 수 있는 매체이기도 하다.
위의 그림을 보면 모든 데이터의 가장 확률이 높은 곳 근처에 1이라는 숫자가 쓰여있는 것을 알 수 있다.
이는 실제 암흑 물질의 위치를 찍은 것인데, 암흑 물질 하나의 위치만 판별하도록 만들어진 코드가 여러 암흑 물질이 있는 경우에도 하나의 암흑 물질의 위치를 아주 잘 찾아낸다는 것을 알 수 있었다.
달리 말하자면 암흑 물질은 질량의 차이가 있고 모든 데이터에는 다른 암흑 물질보다 압도적으로 질량이 큰 암흑 물질 하나가 언제나 존재하는 것을 이를 통해 쉽게 알 수 있었다.&lt;/p&gt;
&lt;h3&gt;Other Approaches&lt;/h3&gt;
&lt;p&gt;다른 접근 방법으로는 물리학적인 모델을 찾아보려고 하였으나 관련 논문들의 내용을 도무지 이해할 수가 없어서 포기하게 되었다.
또한 기본 벤치마크 코드를 조금씩 수정해보고 "느낌"을 얻어보려고 노력하였다.&lt;/p&gt;
&lt;h3&gt;Data Mining&lt;/h3&gt;
&lt;p&gt;누군가 포럼에 문제를 순수하게 데이터 마이닝의 관점에서 보고 모델 등과 무관한 접근 방법을 취하는 이야기를 쓰고 관련된 피쳐를 조금 공개하였다.
이를 살펴보고 적용해보았는데 그럭저럭 괜찮은 결과를 얻을 수 있었지만 더 확장할 수는 없었다.
참고로 관련 글을 포럼에 적었던 사람은 최종적으로 대회 3위를 차지하게 되었다.&lt;/p&gt;
&lt;h3&gt;Evolutionary Algorithms&lt;/h3&gt;
&lt;p&gt;모델을 잘 만들어서 이를 활용하는 방법을 생각하게 되었는데 우선은 두 개의 헤일로가 존재하는 경우의 문제만 시도하였다.
첫 번째 암흑 물질의 위치는 쉽게 알 수 있으므로 이를 가지고 두 번째 헤일로의 위치를 찾는 방법을 고민해보았다.&lt;/p&gt;
&lt;p&gt;첫 번째 암흑 물질의 위치를 알고 있을 때, 이 헤일로가 모든 은하에 가하는 접선 방향의 힘을 각각 은하로부터 제외한 값이 최대한 정규 분포에 가깝게 하는 모델을 찾고자 하였다.
모델 자체는 거리에 반비례, 거리의 제곱에 반비례, 거리의 0.5승에 반비례, 거리의 0.75승에 반비례하는 항들의 합으로 주어지게 하였는데, 각 항은 질량 요소를 갖는 것으로 하였다.
나중에 돌아보니 이는 큰 의미 없이 문제만 어렵게 모델링 한 꼴이 되었지만 당시에는 더 나은 접근 방법을 딱히 떠올리지 못하였다.&lt;/p&gt;
&lt;div class="codehilite"&gt;&lt;pre&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;norm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;e1_pred&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; &lt;span class="n"&gt;fitness&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;위와 같은 적합도 식을 만들고 이를 Pearson/Spearman correlation coefficient 등과 함께 사용하여 조금씩 변형을 가하기는 하였으나 기본적인 형태는 그대로 유지하였다.&lt;/p&gt;
&lt;p&gt;이렇게 찾아야 하는 모델 패러미터와 적합도 식을 만들고 particle swarm optimization으로 최적 모델 패러미터를 찾도록 하였다.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;
&lt;img alt="POS fitting based on signal on sky 103" src="/static/images/normalfit_pearson_103.png" /&gt;
&lt;img alt="POS fitting based on signal on sky 113" src="/static/images/normalfit_pearson_113.png" /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;위의 그림은 두 번째 헤일로의 위치를 예측하도록 한 모델의 결과를 나타낸 것이다.
실제 두 번째 헤일로는 초록색 별로 표시되었고 모델이 예측한 위치는 하얀색 별로 표시하였다.
물론 실제로는 이렇게까지 결과가 훌륭하지 않은 경우들도 여럿 있었다.&lt;/p&gt;
&lt;p&gt;스스로 적용해본 기법은 여기까지가 끝이다.
실제로 대회에 제출한 결과는 벤치마크 코드를 조금 수정해본 것이 다였고, POS 등을 적용한 방법 등의 결과를 제출해보지 못하였다.&lt;/p&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;대회 자체는 나에게 꽤 큰 자극이 되었다.
일차적으로 다른 사람들과 겨룬다는 것 자체가 큰 자극이 된다.
그 밖에도 평소에 연구하는 동안은 잘 활용하지 않는 도구들을 꺼내어 사용하게 되었는데 그 점도 매우 좋았다.&lt;/p&gt;
&lt;p&gt;한가지 느낀 점은 망치를 들고 있으면 모든 것이 못으로 보이기 십상인데 이를 잘 극복해야 할 것이라는 점이다.
내가 아무래도 늘 진화 연산 기법들을 접하다 보니 모든 문제가 단순히 최적화 문제로만 보이고 그렇게 접근하게 되기 쉬웠다.
이는 내가 앞으로 극복하고 포용해야 하는 문제가 될 것이다.&lt;/p&gt;
&lt;p&gt;그리고 마지막으로 대회 1,2위 및 3위가 모두 통계적인 접근 방법을 취했다는 점이 나로 하여금 계속해서 기계학습/데이터 마이닝을 공부하게 하는 자극이 되었다.
1,2위는 조금은 뻔한 베이지안 시각에서 문제에 접근하였고, 3위는 놀랍게도 리니어 모델만 사용한 것으로 보인다.
1,2위는 코드 및 관련 정보를 공개하였으나 3위는 안타깝게도 공개한 것을 찾을 수 없었다.
어찌 되었든 이들의 접근 방법을 보면서 느낀 바도 있고, 여러모로 얻은 것이 많은 대회였다.
다음 글에서는 1,2위가 사용한 베이지안 시각의 접근 방법을 소개하고자 한다.&lt;/p&gt;</summary><category term="kaggle"></category><category term="dark world"></category></entry></feed>